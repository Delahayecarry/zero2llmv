# JSONL å¤šæ¨¡æ€è®­ç»ƒé€‚é…æŒ‡å—

## ğŸ¯ æ¦‚è¿°
å·²æˆåŠŸå°†ä½ çš„ JSONL æ ¼å¼æ•°æ®é€‚é…åˆ° MiniMind-V trainer æ¶æ„ä¸­ã€‚ç°åœ¨å¯ä»¥ä½¿ç”¨å¯¹è¯æ ¼å¼çš„å¤šæ¨¡æ€æ•°æ®è¿›è¡Œè®­ç»ƒã€‚

## ğŸ“ æ–‡ä»¶ç»“æ„
```
zero2LLMV/
â”œâ”€â”€ vlm_dataset.py          # JSONLæ ¼å¼çš„VLMæ•°æ®é›†ç±»
â”œâ”€â”€ trainer_jsonl.py        # é€‚é…çš„è®­ç»ƒå™¨
â”œâ”€â”€ tokenizer/             # ä½ çš„è‡ªå®šä¹‰tokenizer
â”œâ”€â”€ your_data.jsonl        # ä½ çš„JSONLè®­ç»ƒæ•°æ®
â””â”€â”€ your_images/           # å¯¹åº”çš„å›¾ç‰‡æ–‡ä»¶å¤¹
```

## ğŸ“ æ•°æ®æ ¼å¼è¦æ±‚

### JSONLæ–‡ä»¶æ ¼å¼
æ¯è¡Œä¸€ä¸ªJSONå¯¹è±¡ï¼š
```json
{
  "conversations": [
    {
      "role": "user",
      "content": "æä¾›ç»™å®šå›¾åƒçš„ç®€è¦æè¿°ã€‚\n<image>"
    },
    {
      "role": "assistant",
      "content": "æ©„æ¦„æ²¹æ˜¯è‡ªç”±ä½¿ç”¨çš„å¥åº·æˆåˆ†ã€‚"
    }
  ],
  "image": "GCC_train_002582585.jpg"
}
```

### å›¾ç‰‡æ–‡ä»¶å¤¹
- åŒ…å«JSONLä¸­å¼•ç”¨çš„æ‰€æœ‰å›¾ç‰‡æ–‡ä»¶
- æ”¯æŒå¸¸è§å›¾åƒæ ¼å¼ (jpg, png, etc.)
- å›¾ç‰‡ä¼šè¢«è‡ªåŠ¨è°ƒæ•´ä¸º 224x224 åˆ†è¾¨ç‡

## ğŸš€ ä½¿ç”¨æ–¹æ³•

### 1. å‡†å¤‡æ•°æ®
```bash
# å°†ä½ çš„æ•°æ®æ–‡ä»¶æ”¾ç½®åˆ°åˆé€‚ä½ç½®
cp your_training_data.jsonl ./data.jsonl
cp -r your_images/ ./images/
```

### 2. åŸºæœ¬è®­ç»ƒå‘½ä»¤
```bash
python trainer_jsonl.py \
    --data_path data.jsonl \
    --images_path images/ \
    --tokenizer_path tokenizer/ \
    --epochs 4 \
    --batch_size 16 \
    --learning_rate 4e-4
```

### 3. å®Œæ•´å‚æ•°è¯´æ˜
```bash
python trainer_jsonl.py \
    --data_path "path/to/your/data.jsonl" \
    --images_path "path/to/your/images/" \
    --tokenizer_path "path/to/tokenizer/" \
    --epochs 4 \
    --batch_size 16 \
    --learning_rate 4e-4 \
    --max_seq_len 640 \
    --hidden_size 512 \
    --num_hidden_layers 8 \
    --accumulation_steps 1 \
    --grad_clip 1.0 \
    --log_interval 100 \
    --save_interval 1000 \
    --out_dir "./checkpoints" \
    --use_wandb \
    --wandb_project "YourProject"
```

## âš™ï¸ å…³é”®ç‰¹æ€§

### 1. æ™ºèƒ½TokenizeråŠ è½½
- âœ… ä¼˜å…ˆåŠ è½½ä½ æ”¾åœ¨ `tokenizer/` æ–‡ä»¶å¤¹çš„è‡ªå®šä¹‰tokenizer
- âœ… è‡ªåŠ¨å›é€€åˆ°GPT2 tokenizer (å¦‚æœè‡ªå®šä¹‰tokenizerä¸å¯ç”¨)
- âœ… è‡ªåŠ¨æ·»åŠ ç‰¹æ®Štoken: `<|user|>`, `<|assistant|>`, `<|endoftext|>`, `<image>`

### 2. å›¾åƒæ ‡è®°å¤„ç†
- âœ… è‡ªåŠ¨å°†å¯¹è¯ä¸­çš„ `<image>` æ›¿æ¢ä¸ºä½ çš„ `image_special_token`
- âœ… æ”¯æŒå¤šè½®å¯¹è¯æ ¼å¼
- âœ… å›¾åƒé¢„å¤„ç†å’Œæ ‡å‡†åŒ–

### 3. è®­ç»ƒä¼˜åŒ–
- âœ… æ”¯æŒæ··åˆç²¾åº¦è®­ç»ƒ (AMP)
- âœ… æ”¯æŒåˆ†å¸ƒå¼è®­ç»ƒ (DDP) 
- âœ… æ”¯æŒæ¢¯åº¦ç´¯ç§¯
- âœ… æ”¯æŒWandBç›‘æ§

### 4. æ•°æ®éªŒè¯
- âœ… è‡ªåŠ¨éªŒè¯JSONLæ ¼å¼
- âœ… è·³è¿‡æ ¼å¼é”™è¯¯çš„æ•°æ®è¡Œ
- âœ… å¤„ç†ç¼ºå¤±çš„å›¾åƒæ–‡ä»¶

## ğŸ”§ é›†æˆåˆ°ä½ çš„é¡¹ç›®

### æ›¿æ¢ä½ ç°æœ‰çš„VLMDataset
```python
# åœ¨ä½ çš„trainerä¸­æ›¿æ¢è¿™è¡Œï¼š
# from dataset.lm_dataset import VLMDataset

# æ”¹ä¸ºï¼š
from vlm_dataset import create_vlm_dataset

# ç„¶åæ›¿æ¢æ•°æ®é›†åˆ›å»ºä»£ç ï¼š
train_ds = create_vlm_dataset(
    data_path=args.data_path,
    images_path=args.images_path, 
    tokenizer_path=args.tokenizer_path,
    max_length=max_seq_len
)
```

### æ›´æ–°æ¨¡å‹åˆå§‹åŒ–
ç¡®ä¿ä½ çš„æ¨¡å‹æ”¯æŒä»¥ä¸‹æ¥å£ï¼š
```python
# å‰å‘ä¼ æ’­
result = model(input_ids, pixel_values=pixel_values)

# è¿”å›å¯¹è±¡åº”åŒ…å«:
result.logits    # [batch, seq_len, vocab_size]
result.aux_loss  # auxiliary loss tensor
```

## ğŸ“Š æµ‹è¯•éªŒè¯

è¿è¡Œæµ‹è¯•ç¡®ä¿ä¸€åˆ‡æ­£å¸¸ï¼š
```bash
# æµ‹è¯•æ•°æ®é›†
python vlm_dataset.py

# æµ‹è¯•è®­ç»ƒæµç¨‹
python trainer_jsonl.py --epochs 1 --batch_size 2 --log_interval 1
```

## ğŸ¯ ä¸‹ä¸€æ­¥
1. å°†ä½ çš„çœŸå®æ¨¡å‹ `MiniMindVLM` é›†æˆåˆ° `init_model()` å‡½æ•°
2. å°†ä½ çš„çœŸå®æ•°æ®æ›¿æ¢æµ‹è¯•æ•°æ®
3. è°ƒæ•´è¶…å‚æ•°å¼€å§‹è®­ç»ƒ
4. å¯é€‰ï¼šå¯ç”¨WandBç›‘æ§è®­ç»ƒè¿‡ç¨‹

## ğŸ’¡ æç¤º
- å¦‚æœé‡åˆ°å†…å­˜é—®é¢˜ï¼Œå‡å° `batch_size` æˆ– `max_seq_len`
- ä½¿ç”¨ `--accumulation_steps` æ¥æ¨¡æ‹Ÿæ›´å¤§çš„batch size
- å®šæœŸä¿å­˜æ£€æŸ¥ç‚¹é¿å…è®­ç»ƒä¸­æ–­
- ä½¿ç”¨ `--ddp` è¿›è¡Œå¤šGPUè®­ç»ƒ