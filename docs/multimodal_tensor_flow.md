# MiniMindVLM å¤šæ¨¡æ€å¼ é‡æµç¨‹è¯¦è§£

## ğŸ¯ å®Œæ•´æ•°æ®æµè½¬æ¢å›¾

```mermaid
flowchart TD
    %% å¤šæ¨¡æ€è¾“å…¥å¤„ç†
    subgraph MultimodalInput["ğŸŒŸ å¤šæ¨¡æ€è¾“å…¥å¤„ç†"]
        direction TB
        
        %% æ–‡æœ¬è¾“å…¥åˆ†æ”¯
        subgraph TextBranch["ğŸ“ æ–‡æœ¬å¤„ç†åˆ†æ”¯"]
            T1["åŸå§‹æ–‡æœ¬<br/>ğŸ’¬ 'è¯·æè¿°å›¾ç‰‡: @@@@...'<br/>ğŸ“ åŒ…å«196ä¸ª@å ä½ç¬¦"]
            T2["Tokenization<br/>ğŸ”¤ Text â†’ Token IDs<br/>ğŸ“Š [batch_size, seq_len]"]
            T3["è¯åµŒå…¥å±‚<br/>ğŸ“š Embedding Lookup<br/>ğŸ“ [batch_size, seq_len, hidden_size]"]
            
            T1 --> T2 --> T3
        end
        
        %% å›¾åƒè¾“å…¥åˆ†æ”¯  
        subgraph ImageBranch["ğŸ–¼ï¸ å›¾åƒå¤„ç†åˆ†æ”¯"]
            I1["åŸå§‹å›¾åƒ<br/>ğŸ–¼ï¸ PIL Image<br/>ğŸ“ ä»»æ„å°ºå¯¸ (HÃ—WÃ—3)"]
            I2["æ ¼å¼æ ‡å‡†åŒ–<br/>ğŸ”„ RGB Conversion<br/>ğŸ“ ç¡®ä¿3é€šé“æ ¼å¼"]
            I3["CLIPé¢„å¤„ç†<br/>âš™ï¸ Resize + Normalize<br/>ğŸ“Š [1, 3, 224, 224]"]
            I4["æ‰¹é‡å¤„ç†<br/>ğŸ“¦ Batch Formation<br/>ğŸ“Š [batch_size, num_images, 3, 224, 224]"]
            
            I1 --> I2 --> I3 --> I4
        end
    end
    
    %% ç‰¹å¾ç¼–ç é˜¶æ®µ
    subgraph FeatureEncoding["ğŸ”¬ ç‰¹å¾ç¼–ç é˜¶æ®µ"]
        direction TB
        
        %% è§†è§‰ç¼–ç è¯¦ç»†æµç¨‹
        subgraph VisionEncoding["ğŸ‘ï¸ è§†è§‰ç‰¹å¾ç¼–ç "]
            V1["CLIP ViTç¼–ç <br/>ğŸ§  Vision Transformer<br/>ğŸ”’ frozen parameters"]
            V2["PatchåµŒå…¥<br/>ğŸ“Š [batch_size, num_images, 197, 768]<br/>ğŸ¯ 1Ã—CLS + 196Ã—patches"]
            V3["ç§»é™¤CLS token<br/>âœ‚ï¸ Remove [CLS]<br/>ğŸ“‰ [batch_size, num_images, 196, 768]"]
            V4["è§†è§‰æŠ•å½±<br/>ğŸ¯ Linear Projection<br/>ğŸ“ 768 â†’ hidden_size"]
            V5["æŠ•å½±åç‰¹å¾<br/>âœ… Projected Features<br/>ğŸ“Š [batch_size, num_images, 196, hidden_size]"]
            
            V1 --> V2 --> V3 --> V4 --> V5
        end
        
        %% è¿æ¥è¾“å…¥åˆ†æ”¯åˆ°ç¼–ç é˜¶æ®µ
        I4 --> V1
    end
    
    %% å¤šæ¨¡æ€ç‰¹å¾èåˆ
    subgraph ModalityFusion["ğŸ”— è·¨æ¨¡æ€ç‰¹å¾èåˆ"]
        direction TB
        
        F1["å ä½ç¬¦åŒ¹é…<br/>ğŸ” Image Token Detection<br/>ğŸ¯ å®šä½'@'Ã—196åºåˆ—ä½ç½®"]
        F2["ç‰¹å¾æ›¿æ¢ç®—æ³•<br/>ğŸ§® Feature Substitution<br/>ğŸ”„ é€batchå¤„ç†"]
        F3["åºåˆ—é‡æ„<br/>ğŸ”§ Sequence Reconstruction<br/>ğŸ§© text_prefix + vision + text_suffix"]
        F4["èåˆåºåˆ—<br/>ğŸŠ Multimodal Sequence<br/>ğŸ“Š [batch_size, seq_len, hidden_size]"]
        
        %% è¿æ¥æ–‡æœ¬å’Œè§†è§‰åˆ†æ”¯
        T3 --> F1
        V5 --> F2
        F1 --> F2 --> F3 --> F4
        
        %% èåˆç®—æ³•è¯¦ç»†æ­¥éª¤
        subgraph FusionDetail["ğŸ”¬ èåˆç®—æ³•è¯¦è§£"]
            direction LR
            FD1["ğŸ” 1. æ‰«ætokenåºåˆ—"]
            FD2["ğŸ“ 2. å®šä½å›¾åƒå ä½ç¬¦"]
            FD3["ğŸ¯ 3. æå–å¯¹åº”è§†è§‰ç‰¹å¾"]
            FD4["âœ‚ï¸ 4. åˆ‡åˆ†æ–‡æœ¬åºåˆ—"]
            FD5["ğŸ§© 5. æ‹¼æ¥å¤šæ¨¡æ€ç‰¹å¾"]
            FD6["ğŸ“ 6. æˆªæ–­åˆ°æœ€å¤§é•¿åº¦"]
            
            FD1 --> FD2 --> FD3 --> FD4 --> FD5 --> FD6
        end
        
        F2 -.-> FusionDetail
    end
    
    %% Transformerå¤„ç†é˜¶æ®µ
    subgraph TransformerProcessing["ğŸ§  Transformerå¤šæ¨¡æ€å¤„ç†"]
        direction TB
        
        %% ä½ç½®ç¼–ç 
        subgraph PositionalEncoding["ğŸ“ ä½ç½®ç¼–ç å¤„ç†"]
            PE1["RoPEé¢„è®¡ç®—<br/>ğŸŒ€ Rotary Position Embedding<br/>ğŸ“Š cos/siné¢‘ç‡è¡¨"]
            PE2["ä½ç½®ç´¢å¼•<br/>ğŸ“‹ Position Indices<br/>ğŸ¯ [start_pos : start_pos + seq_len]"]
            PE3["ä½ç½®åµŒå…¥<br/>ğŸ¯ Position Embeddings<br/>ğŸ“Š (cos, sin) tuples"]
            
            PE1 --> PE2 --> PE3
        end
        
        %% å¤šå±‚Transformer
        subgraph LayerStack["ğŸ“š Transformerå±‚å †æ ˆ"]
            direction TB
            
            L0["Layer 0: MiniMindBlock<br/>âš¡ MultiHead Attention + FFN/MoE<br/>ğŸ“Š [B, L, H] â†’ [B, L, H]"]
            L1["Layer 1: MiniMindBlock<br/>âš¡ Cross-modal Attention<br/>ğŸ“Š è§†è§‰-æ–‡æœ¬ä¿¡æ¯äº¤äº’"]
            L2["Layer 2: MiniMindBlock<br/>âš¡ Deep Semantic Fusion<br/>ğŸ“Š é«˜å±‚è¯­ä¹‰ç†è§£"]
            LN["Layer N-1: MiniMindBlock<br/>âš¡ Final Representation<br/>ğŸ“Š æœ€ç»ˆå¤šæ¨¡æ€è¡¨ç¤º"]
            
            L0 --> L1 --> L2 --> LN
            
            %% æ¯å±‚çš„è¯¦ç»†å¤„ç†
            subgraph LayerDetails["ğŸ”¬ å•å±‚è¯¦ç»†å¤„ç†"]
                LD1["è¾“å…¥å±‚å½’ä¸€åŒ–<br/>ğŸ“ Pre-Norm RMSNorm"]
                LD2["å¤šå¤´è‡ªæ³¨æ„åŠ›<br/>ğŸ‘ï¸ Multi-Head Attention<br/>ğŸ¯ Q, K, VæŠ•å½± + æ³¨æ„åŠ›è®¡ç®—"]
                LD3["æ®‹å·®è¿æ¥<br/>ğŸ”— Residual Connection"]
                LD4["å‰é¦ˆç½‘ç»œ<br/>âš¡ FFN/MoE Processing"]
                LD5["è¾“å‡ºæ®‹å·®è¿æ¥<br/>ğŸ”— Final Residual"]
                
                LD1 --> LD2 --> LD3 --> LD4 --> LD5
            end
            
            L0 -.-> LayerDetails
        end
        
        %% è¿æ¥èåˆè¾“å‡ºåˆ°Transformer
        F4 --> PE1
        PE3 --> L0
        F4 --> L0
        
        %% æœ€ç»ˆè¾“å‡ºå¤„ç†
        subgraph OutputProcessing["ğŸ“¤ è¾“å‡ºå¤„ç†"]
            OP1["æœ€ç»ˆå±‚å½’ä¸€åŒ–<br/>ğŸ“ Final RMSNorm<br/>ğŸ“Š [batch_size, seq_len, hidden_size]"]
            OP2["è¯­è¨€å»ºæ¨¡å¤´<br/>ğŸ¯ LM Head Linear<br/>ğŸ“Š hidden_size â†’ vocab_size"]
            OP3["æ¦‚ç‡åˆ†å¸ƒ<br/>ğŸ“ˆ Softmax Probabilities<br/>ğŸ“Š [batch_size, seq_len, vocab_size]"]
            
            OP1 --> OP2 --> OP3
        end
        
        LN --> OP1
    end
    
    %% KVç¼“å­˜æœºåˆ¶
    subgraph KVCacheMechanism["ğŸ’¾ KVç¼“å­˜ä¼˜åŒ–æœºåˆ¶"]
        direction TB
        
        KC1["åˆå§‹ç¼–ç é˜¶æ®µ<br/>ğŸ’½ Full Context Encoding<br/>ğŸ“Š å¤„ç†å®Œæ•´å¤šæ¨¡æ€åºåˆ—"]
        KC2["ç¼“å­˜å­˜å‚¨<br/>ğŸ—„ï¸ Cache Storage<br/>ğŸ“Š Key: [B, L, H], Value: [B, L, H]"]
        KC3["å¢é‡ç”Ÿæˆ<br/>âš¡ Incremental Generation<br/>ğŸ“Š åªå¤„ç†æ–°token [B, 1, H]"]
        KC4["ç¼“å­˜æ›´æ–°<br/>ğŸ”„ Cache Concatenation<br/>ğŸ“Š æ‹¼æ¥å†å²å’Œæ–°çš„K, V"]
        KC5["é«˜æ•ˆæ³¨æ„åŠ›<br/>ğŸš€ Efficient Attention<br/>ğŸ¯ Q_new @ K_cached.T"]
        
        KC1 --> KC2 --> KC3 --> KC4 --> KC5
        KC5 -.-> KC3
        
        %% æ€§èƒ½ä¼˜åŒ–è¯´æ˜
        subgraph CachePerf["ğŸ“ˆ ç¼“å­˜æ€§èƒ½ä¼˜åŒ–"]
            CP1["â° æ—¶é—´å¤æ‚åº¦: O(n) vs O(nÂ²)"]
            CP2["ğŸ’¾ ç©ºé—´å¤æ‚åº¦: ç¼“å­˜æ¢æ—¶é—´"]
            CP3["ğŸš€ ç”ŸæˆåŠ é€Ÿ: 10-100å€æå‡"]
        end
        
        KC5 -.-> CachePerf
    end
    
    %% è¿æ¥Transformeråˆ°ç¼“å­˜æœºåˆ¶
    L0 -.-> KC1
    L1 -.-> KC2
    L2 -.-> KC3
    LN -.-> KC4
    
    %% MoEå¤„ç†åˆ†æ”¯ (å¦‚æœå¯ç”¨)
    subgraph MoEProcessing["ğŸ¯ MoEä¸“å®¶æ··åˆå¤„ç†"]
        direction TB
        
        ME1["MoEé—¨æ§ç½‘ç»œ<br/>ğŸšª Expert Router<br/>ğŸ“Š è®¡ç®—ä¸“å®¶é€‰æ‹©æ¦‚ç‡"]
        ME2["TopKä¸“å®¶é€‰æ‹©<br/>ğŸ” Expert Selection<br/>ğŸ¯ é€‰æ‹©top-kä¸ªæœ€ç›¸å…³ä¸“å®¶"]
        ME3["ä¸“å®¶å¹¶è¡Œè®¡ç®—<br/>âš¡ Parallel Expert FFN<br/>ğŸ§  å¤šä¸ªä¸“å®¶ç‹¬ç«‹å¤„ç†"]
        ME4["åŠ æƒèåˆ<br/>âš–ï¸ Weighted Aggregation<br/>ğŸ”— åŸºäºé—¨æ§æƒé‡åˆå¹¶ç»“æœ"]
        ME5["è´Ÿè½½å‡è¡¡æŸå¤±<br/>ğŸ“Š Auxiliary Loss<br/>ğŸ¯ ç¡®ä¿ä¸“å®¶ä½¿ç”¨å‡è¡¡"]
        
        ME1 --> ME2 --> ME3 --> ME4 --> ME5
        
        %% MoEä¼˜åŠ¿è¯´æ˜
        subgraph MoEAdvantages["ğŸŒŸ MoEæ¶æ„ä¼˜åŠ¿"]
            MA1["ğŸ“ˆ æ¨¡å‹å®¹é‡æ‰©å±•<br/>å¢åŠ ä¸“å®¶ä¸å¢åŠ è®¡ç®—"]
            MA2["âš¡ æ¨ç†æ•ˆç‡<br/>æ¯æ¬¡åªæ¿€æ´»éƒ¨åˆ†ä¸“å®¶"]
            MA3["ğŸ¯ ä¸“ä¸šåŒ–å­¦ä¹ <br/>ä¸åŒä¸“å®¶å¤„ç†ä¸åŒæ¨¡å¼"]
        end
        
        ME4 -.-> MoEAdvantages
    end
    
    %% æ¡ä»¶è¿æ¥MoE
    L0 -.-> |"if use_moe"| ME1
    L1 -.-> |"if use_moe"| ME1
    L2 -.-> |"if use_moe"| ME1
    LN -.-> |"if use_moe"| ME1
    
    %% æ ·å¼å®šä¹‰
    classDef inputStyle fill:#e3f2fd,stroke:#1976d2,stroke-width:2px,color:#000
    classDef encodingStyle fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px,color:#000
    classDef fusionStyle fill:#e8f5e8,stroke:#388e3c,stroke-width:2px,color:#000
    classDef transformerStyle fill:#fff3e0,stroke:#f57c00,stroke-width:2px,color:#000
    classDef cacheStyle fill:#f1f8e9,stroke:#689f38,stroke-width:2px,color:#000
    classDef moeStyle fill:#fce4ec,stroke:#c2185b,stroke-width:2px,color:#000
    
    class T1,T2,T3,I1,I2,I3,I4 inputStyle
    class V1,V2,V3,V4,V5 encodingStyle
    class F1,F2,F3,F4,FD1,FD2,FD3,FD4,FD5,FD6 fusionStyle
    class PE1,PE2,PE3,L0,L1,L2,LN,LD1,LD2,LD3,LD4,LD5,OP1,OP2,OP3 transformerStyle
    class KC1,KC2,KC3,KC4,KC5,CP1,CP2,CP3 cacheStyle
    class ME1,ME2,ME3,ME4,ME5,MA1,MA2,MA3 moeStyle
```

## ğŸ” å…³é”®å¼ é‡å˜æ¢ç¤ºä¾‹

```mermaid
flowchart LR
    subgraph TensorExamples["ğŸ“Š å…·ä½“å¼ é‡å˜æ¢ç¤ºä¾‹"]
        direction TB
        
        %% è¾“å…¥ç¤ºä¾‹
        subgraph InputExample["ğŸ“¥ è¾“å…¥ç¤ºä¾‹"]
            EI1["æ–‡æœ¬: 'è¯·æè¿°è¿™å¼ å›¾ç‰‡:' + '@'Ã—196<br/>ğŸ“Š token_ids: [1,2,3,4,34,34,...,34]<br/>ğŸ“ shape: [1, 200]"]
            EI2["å›¾åƒ: cat.jpg (512Ã—512Ã—3)<br/>ğŸ“Š pixel_values: [0.485,0.456,...]<br/>ğŸ“ shape: [1, 1, 3, 224, 224]"]
        end
        
        %% ç¼–ç ç¤ºä¾‹
        subgraph EncodingExample["ğŸ”¬ ç¼–ç ç¤ºä¾‹"]  
            EE1["æ–‡æœ¬åµŒå…¥<br/>ğŸ“Š text_embeds<br/>ğŸ“ [1, 200, 768]"]
            EE2["è§†è§‰ç‰¹å¾<br/>ğŸ“Š vision_features<br/>ğŸ“ [1, 1, 196, 768]"]
            EE3["æŠ•å½±ç‰¹å¾<br/>ğŸ“Š projected_vision<br/>ğŸ“ [1, 1, 196, 768]"]
        end
        
        %% èåˆç¤ºä¾‹
        subgraph FusionExample["ğŸ”— èåˆç¤ºä¾‹"]
            EF1["å ä½ç¬¦åŒ¹é…<br/>ğŸ¯ æ‰¾åˆ°ä½ç½® [5:201]<br/>ğŸ“ 196ä¸ª@ç¬¦å·ä½ç½®"]
            EF2["ç‰¹å¾æ›¿æ¢<br/>ğŸ”„ [prefix] + [vision] + [suffix]<br/>ğŸ“Š [1, 200, 768]"]
        end
        
        %% Transformerç¤ºä¾‹
        subgraph TransformerExample["ğŸ§  Transformerç¤ºä¾‹"]
            ET1["å¤šå¤´æ³¨æ„åŠ›<br/>ğŸ‘ï¸ Q,K,V: [1, 200, 768]<br/>ğŸ¯ è§†è§‰-æ–‡æœ¬äº¤äº’"]
            ET2["FFN/MoEå¤„ç†<br/>âš¡ hidden: [1, 200, 768]<br/>ğŸ”„ æ·±å±‚ç‰¹å¾å˜æ¢"]
            ET3["æœ€ç»ˆè¾“å‡º<br/>ğŸ“¤ logits: [1, 200, 50000]<br/>ğŸ“ˆ è¯æ±‡è¡¨æ¦‚ç‡åˆ†å¸ƒ"]
        end
        
        %% æ•°æ®æµè¿æ¥
        EI1 --> EE1
        EI2 --> EE2
        EE2 --> EE3
        EE1 --> EF1
        EE3 --> EF2
        EF2 --> ET1
        ET1 --> ET2
        ET2 --> ET3
    end
```

## âš¡ æ€§èƒ½ä¼˜åŒ–ç­–ç•¥

```mermaid
mindmap
    root((âš¡ æ€§èƒ½ä¼˜åŒ–<br/>ç­–ç•¥))
        (ğŸ’¾ å†…å­˜ä¼˜åŒ–)
            æ¢¯åº¦æ£€æŸ¥ç‚¹
            æ··åˆç²¾åº¦è®­ç»ƒ
            æ‰¹æ¬¡å¤§å°è°ƒä¼˜
            åºåˆ—é•¿åº¦æˆªæ–­
        (ğŸš€ æ¨ç†åŠ é€Ÿ)  
            KVç¼“å­˜æœºåˆ¶
            Flash Attention
            æ¨¡å‹é‡åŒ–
            æ‰¹é‡æ¨ç†
        (ğŸ¯ æ¶æ„ä¼˜åŒ–)
            MoEç¨€ç–æ¿€æ´»
            GQAæ³¨æ„åŠ›
            å‚æ•°å…±äº«
            æ—©åœæœºåˆ¶
        (ğŸ”§ å·¥ç¨‹ä¼˜åŒ–)
            å¤šGPUå¹¶è¡Œ
            å¼‚æ­¥æ•°æ®åŠ è½½
            å†…å­˜æ˜ å°„
            ç¼“å­˜é¢„çƒ­
```

## ğŸ“ˆ å¤šæ¨¡æ€æ³¨æ„åŠ›å¯è§†åŒ–

```mermaid
graph TD
    subgraph AttentionVisualization["ğŸ‘ï¸ å¤šæ¨¡æ€æ³¨æ„åŠ›æœºåˆ¶å¯è§†åŒ–"]
        direction TB
        
        %% è¾“å…¥åºåˆ—è¡¨ç¤º
        subgraph InputSequence["ğŸ“ è¾“å…¥åºåˆ—ç»“æ„"]
            IS1["[BOS] è¯· æè¿° è¿™å¼  å›¾ç‰‡"]
            IS2["[IMG_1] [IMG_2] ... [IMG_196]"] 
            IS3["å®ƒ æ˜¯ ä¸€åª çŒ« [EOS]"]
            
            IS1 --> IS2 --> IS3
        end
        
        %% æ³¨æ„åŠ›æ¨¡å¼
        subgraph AttentionPatterns["ğŸ¯ æ³¨æ„åŠ›æ¨¡å¼åˆ†æ"]
            direction LR
            
            AP1["æ–‡æœ¬-æ–‡æœ¬æ³¨æ„åŠ›<br/>ğŸ“â†’ğŸ“<br/>è¯­æ³•è¯­ä¹‰å…³ç³»"]
            AP2["è§†è§‰-è§†è§‰æ³¨æ„åŠ›<br/>ğŸ‘ï¸â†’ğŸ‘ï¸<br/>ç©ºé—´ä½ç½®å…³ç³»"]
            AP3["æ–‡æœ¬-è§†è§‰æ³¨æ„åŠ›<br/>ğŸ“â†’ğŸ‘ï¸<br/>è·¨æ¨¡æ€è¯­ä¹‰å¯¹é½"]
            AP4["è§†è§‰-æ–‡æœ¬æ³¨æ„åŠ›<br/>ğŸ‘ï¸â†’ğŸ“<br/>è§†è§‰å¼•å¯¼ç†è§£"]
            
            AP1 --> AP3
            AP2 --> AP4
            AP3 --> AP4
        end
        
        %% æ³¨æ„åŠ›æƒé‡çŸ©é˜µ
        subgraph AttentionMatrix["ğŸ“Š æ³¨æ„åŠ›æƒé‡çŸ©é˜µ"]
            AM1["æ–‡æœ¬ Query vs æ–‡æœ¬ Key<br/>ğŸ”µ é«˜æƒé‡: è¯­æ³•ä¾èµ–"]
            AM2["æ–‡æœ¬ Query vs è§†è§‰ Key<br/>ğŸŸ¢ é«˜æƒé‡: è§†è§‰æè¿°è¯"]
            AM3["è§†è§‰ Query vs æ–‡æœ¬ Key<br/>ğŸŸ¡ é«˜æƒé‡: æŒ‡ç¤ºä»£è¯"]
            AM4["è§†è§‰ Query vs è§†è§‰ Key<br/>ğŸ”´ é«˜æƒé‡: ç›¸é‚»patch"]
        end
        
        IS2 --> AttentionPatterns
        AttentionPatterns --> AttentionMatrix
    end
```

## ğŸ”¬ ç‰¹å¾èåˆç®—æ³•è¯¦è§£

```python
def count_vision_proj_detailed(self, tokens, h, vision_tensors, seqlen):
    """
    è§†è§‰ç‰¹å¾èåˆç®—æ³• - è¯¦ç»†å®ç°è§£æ
    
    æ ¸å¿ƒæ€æƒ³: å°†å›¾åƒpatchç‰¹å¾æ›¿æ¢æ–‡æœ¬åºåˆ—ä¸­çš„å ä½ç¬¦token
    ç®—æ³•å¤æ‚åº¦: O(batch_size Ã— seq_len Ã— image_patch_size)
    å†…å­˜å¤æ‚åº¦: O(batch_size Ã— seq_len Ã— hidden_size)
    """
    
    # ç¬¬ä¸€æ­¥: å›¾åƒå ä½ç¬¦å®šä½ç®—æ³•
    def find_image_placeholder_positions(tokens, image_ids):
        """
        ä½¿ç”¨æ»‘åŠ¨çª—å£ç®—æ³•å®šä½å›¾åƒå ä½ç¬¦åºåˆ—
        
        æ—¶é—´å¤æ‚åº¦: O(batch_size Ã— seq_len Ã— len(image_ids))
        ç©ºé—´å¤æ‚åº¦: O(batch_size Ã— num_matches)
        """
        image_ids_tensor = torch.tensor(image_ids).to(tokens.device)
        window_size = len(image_ids)
        
        # åˆ›å»ºæ»‘åŠ¨çª—å£è§†å›¾: [batch_size, num_windows, window_size]
        tokens_windowed = tokens.unfold(1, window_size, 1)
        
        # é€çª—å£åŒ¹é…: æ‰€æœ‰tokenéƒ½å¿…é¡»å®Œå…¨åŒ¹é…
        matches = (tokens_windowed == image_ids_tensor).all(dim=2)
        
        # æ„å»ºåŒ¹é…ä½ç½®ç´¢å¼•å­—å…¸
        match_positions = {}
        for batch_idx in range(tokens.size(0)):
            if matches[batch_idx].any():
                positions = matches[batch_idx].nonzero(as_tuple=True)[0]
                match_positions[batch_idx] = [
                    (pos.item(), pos.item() + window_size - 1) 
                    for pos in positions
                ]
        
        return match_positions if match_positions else None
    
    # ç¬¬äºŒæ­¥: è§†è§‰ç‰¹å¾æŠ•å½±å˜æ¢
    if vision_tensors is not None:
        # ç»´åº¦å¯¹é½: [batch_size, num_images, 196, clip_dim] â†’ [batch_size, num_images, 196, hidden_size]
        vision_projected = self.vision_proj(vision_tensors)
        
        # ç¡®ä¿æ‰¹æ¬¡ç»´åº¦å­˜åœ¨
        if len(vision_projected.shape) == 3:
            vision_projected = vision_projected.unsqueeze(0)
    
    # ç¬¬ä¸‰æ­¥: å¤šæ¨¡æ€åºåˆ—é‡æ„ç®—æ³•
    image_positions = find_image_placeholder_positions(tokens, self.params.image_ids)
    
    if vision_tensors is not None and image_positions:
        reconstructed_sequences = []
        
        for batch_idx in range(h.size(0)):
            if batch_idx in image_positions:
                # å½“å‰æ‰¹æ¬¡åŒ…å«å›¾åƒï¼Œéœ€è¦ç‰¹å¾èåˆ
                current_sequence = h[batch_idx]  # [seq_len, hidden_size]
                image_idx = 0
                
                # é€ä¸ªæ›¿æ¢å›¾åƒå ä½ç¬¦
                for start_pos, end_pos in image_positions[batch_idx]:
                    if image_idx < vision_projected.size(1):
                        # è·å–å½“å‰å›¾åƒçš„patchç‰¹å¾
                        current_image_features = vision_projected[batch_idx][image_idx]  # [196, hidden_size]
                        
                        # æ‰§è¡Œå¼ é‡æ‹¼æ¥: å‰ç¼€ + è§†è§‰ç‰¹å¾ + åç¼€
                        sequence_parts = [
                            current_sequence[:start_pos],           # å›¾åƒå‰çš„æ–‡æœ¬ç‰¹å¾
                            current_image_features,                 # æŠ•å½±åçš„è§†è§‰ç‰¹å¾
                            current_sequence[end_pos + 1:]          # å›¾åƒåçš„æ–‡æœ¬ç‰¹å¾
                        ]
                        
                        # æ‹¼æ¥å¹¶æˆªæ–­åˆ°æœ€å¤§åºåˆ—é•¿åº¦
                        current_sequence = torch.cat(sequence_parts, dim=0)[:seqlen]
                        image_idx += 1
                
                reconstructed_sequences.append(current_sequence)
            else:
                # å½“å‰æ‰¹æ¬¡ä¸åŒ…å«å›¾åƒï¼Œä¿æŒåŸæ–‡æœ¬ç‰¹å¾
                reconstructed_sequences.append(h[batch_idx])
        
        # é‡æ–°å †å ä¸ºæ‰¹æ¬¡å¼ é‡
        return torch.stack(reconstructed_sequences, dim=0)
    
    # å¦‚æœæ²¡æœ‰è§†è§‰è¾“å…¥ï¼Œç›´æ¥è¿”å›åŸæ–‡æœ¬ç‰¹å¾
    return h
```

## ğŸ§® è®¡ç®—å¤æ‚åº¦åˆ†æ

```mermaid
graph TD
    subgraph ComplexityAnalysis["ğŸ§® è®¡ç®—å¤æ‚åº¦åˆ†æ"]
        direction TB
        
        %% æ—¶é—´å¤æ‚åº¦
        subgraph TimeComplexity["â° æ—¶é—´å¤æ‚åº¦"]
            TC1["è§†è§‰ç¼–ç : O(HÃ—WÃ—C)<br/>ğŸ¯ CLIP ViTå›ºå®šå¼€é”€"]
            TC2["ç‰¹å¾æŠ•å½±: O(NÃ—PÃ—H)<br/>ğŸ¯ çº¿æ€§å˜æ¢å¼€é”€"]
            TC3["å ä½ç¬¦åŒ¹é…: O(BÃ—LÃ—I)<br/>ğŸ¯ æ»‘åŠ¨çª—å£æœç´¢"]
            TC4["åºåˆ—é‡æ„: O(BÃ—LÃ—H)<br/>ğŸ¯ å¼ é‡æ‹¼æ¥æ“ä½œ"]
            TC5["Transformer: O(BÃ—LÂ²Ã—H)<br/>ğŸ¯ è‡ªæ³¨æ„åŠ›æœºåˆ¶"]
            TC6["KVç¼“å­˜ä¼˜åŒ–: O(BÃ—LÃ—H)<br/>ğŸ¯ å¢é‡è®¡ç®—"]
        end
        
        %% ç©ºé—´å¤æ‚åº¦
        subgraph SpaceComplexity["ğŸ’¾ ç©ºé—´å¤æ‚åº¦"]
            SC1["æ–‡æœ¬ç‰¹å¾: O(BÃ—LÃ—H)<br/>ğŸ“Š ä¸»è¦å†…å­˜å ç”¨"]
            SC2["è§†è§‰ç‰¹å¾: O(BÃ—NÃ—PÃ—H)<br/>ğŸ“Š å›¾åƒpatchå­˜å‚¨"]
            SC3["æ³¨æ„åŠ›æƒé‡: O(BÃ—NhÃ—LÂ²)<br/>ğŸ“Š æ³¨æ„åŠ›çŸ©é˜µ"]
            SC4["KVç¼“å­˜: O(BÃ—LÃ—HÃ—2Ã—Nl)<br/>ğŸ“Š å†å²ä¸Šä¸‹æ–‡"]
            SC5["MoEæ¿€æ´»: O(BÃ—LÃ—EÃ—H)<br/>ğŸ“Š ä¸“å®¶å‚æ•°ç¼“å­˜"]
        end
        
        %% ä¼˜åŒ–ç­–ç•¥
        subgraph OptimizationStrategies["ğŸš€ ä¼˜åŒ–ç­–ç•¥"]
            OS1["æ··åˆç²¾åº¦: å‡å°‘50%å†…å­˜<br/>âš¡ FP16æ¨ç†"]
            OS2["æ¢¯åº¦æ£€æŸ¥ç‚¹: æ—¶é—´æ¢ç©ºé—´<br/>ğŸ’¾ é‡è®¡ç®—ç­–ç•¥"]
            OS3["åºåˆ—å¹¶è¡Œ: åˆ†å¸ƒå¼å¤„ç†<br/>ğŸŒ å¤šGPUåä½œ"]
            OS4["åŠ¨æ€batching: è‡ªé€‚åº”æ‰¹æ¬¡<br/>ğŸ“Š æé«˜ååé‡"]
        end
        
        %% æ€§èƒ½å¯¹æ¯”
        subgraph PerformanceComparison["ğŸ“ˆ æ€§èƒ½å¯¹æ¯”"]
            PC1["ä¼ ç»Ÿæ–¹æ¡ˆ: 2Ã—æ¨¡å‹å‚æ•°<br/>ğŸŒ ç‹¬ç«‹è§†è§‰+è¯­è¨€æ¨¡å‹"]
            PC2["MiniMindVLM: 1Ã—æ¨¡å‹å‚æ•°<br/>âš¡ ç»Ÿä¸€å¤šæ¨¡æ€æ¶æ„"]
            PC3["æ¨ç†é€Ÿåº¦: 3-5å€æå‡<br/>ğŸš€ KVç¼“å­˜+å‚æ•°å…±äº«"]
            PC4["å†…å­˜ä½¿ç”¨: 30-50%å‡å°‘<br/>ğŸ’¾ æ¶æ„ä¼˜åŒ–æ•ˆæœ"]
        end
    end
```

---

## ğŸ“ æ€»ç»“

MiniMindVLM é€šè¿‡ç²¾å¿ƒè®¾è®¡çš„å¤šæ¨¡æ€å¼ é‡æµå¤„ç†ç®¡é“ï¼Œå®ç°äº†é«˜æ•ˆçš„è§†è§‰-è¯­è¨€ç†è§£ä¸ç”Ÿæˆï¼š

### ğŸŒŸ æ ¸å¿ƒä¼˜åŠ¿

1. **ğŸ”— ç»Ÿä¸€æ¶æ„**: å•ä¸€Transformerå¤„ç†å¤šæ¨¡æ€ä¿¡æ¯ï¼Œé¿å…æ¨¡æ€é—´çš„ç‰¹å¾å¯¹é½é—®é¢˜
2. **âš¡ é«˜æ•ˆèåˆ**: æ—©æœŸç‰¹å¾èåˆç­–ç•¥ï¼Œåœ¨ç¼–ç é˜¶æ®µå°±å®Œæˆè§†è§‰-æ–‡æœ¬å¯¹é½
3. **ğŸ’¾ å†…å­˜ä¼˜åŒ–**: KVç¼“å­˜æœºåˆ¶æ˜¾è‘—å‡å°‘æ¨ç†æ—¶çš„è®¡ç®—å¼€é”€
4. **ğŸ¯ ç«¯åˆ°ç«¯**: æ•´ä¸ªå¤šæ¨¡æ€ç®¡é“å¯è”åˆä¼˜åŒ–ï¼Œè·å¾—æ›´å¥½çš„å¯¹é½æ•ˆæœ
5. **ğŸ”§ å¯æ‰©å±•**: å®Œå…¨å…¼å®¹MoEã€GQAç­‰å…ˆè¿›æ¶æ„ç‰¹æ€§

### ğŸ“Š æŠ€æœ¯æŒ‡æ ‡

- **å»¶è¿Ÿä¼˜åŒ–**: KVç¼“å­˜æœºåˆ¶æä¾›10-100å€ç”ŸæˆåŠ é€Ÿ
- **å†…å­˜æ•ˆç‡**: ç›¸æ¯”ä¼ ç»Ÿæ–¹æ¡ˆå‡å°‘30-50%å†…å­˜ä½¿ç”¨
- **æ¨¡å‹ç²¾åº¦**: ç«¯åˆ°ç«¯è®­ç»ƒè·å¾—æ›´å¥½çš„å¤šæ¨¡æ€å¯¹é½æ•ˆæœ
- **æ¶æ„çµæ´»**: æ”¯æŒä¸åŒè§„æ¨¡çš„è§†è§‰ç¼–ç å™¨å’Œè¯­è¨€æ¨¡å‹ç»„åˆ

è¿™ç§è®¾è®¡æ—¢ä¿æŒäº†å¼ºå¤§çš„å¤šæ¨¡æ€ç†è§£èƒ½åŠ›ï¼Œåˆåœ¨å·¥ç¨‹å®ç°ä¸Šè¾¾åˆ°äº†ç”Ÿäº§çº§åˆ«çš„æ•ˆç‡è¦æ±‚ã€‚