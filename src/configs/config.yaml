# Zero2LLMV 训练配置
# 
# 这是 Zero2LLMV 训练框架的默认配置文件。
# 所有参数都有合理的默认值并包含详细的文档说明。
# 您可以通过命令行参数或环境变量覆盖任何参数。
#
# 优先级顺序（从低到高）：
# 1. 此 YAML 文件
# 2. 环境变量（用于敏感数据如 API 密钥）  
# 3. 命令行参数（最高优先级）

# =============================================================================
# 模型配置
# =============================================================================
model:
  # 模型架构类型
  # 选项："llm"（仅语言模型），"vlm"（视觉语言模型）
  model_type: "vlm"
  
  # 自定义模型配置文件路径（可选）
  # 留空以使用默认配置
  model_config_path: ""

# =============================================================================
# 数据配置  
# =============================================================================
data:
  # 训练数据目录路径
  # 应包含已处理的训练样本
  data_path: "data/processed"
  
  # 分词的最大序列长度
  # 范围：1-8192，典型值：512, 1024, 2048
  # 更长的序列需要更多 GPU 内存
  max_seq_length: 512
  
  # 每个 GPU 的训练批次大小
  # 范围：1-1024，典型值：4, 8, 16, 32
  # 更大的批次可能提高稳定性但需要更多内存
  batch_size: 8
  
  # 数据加载器工作进程数
  # 范围：0-64，典型值：2, 4, 8
  # 0 仅使用主进程（较慢但内存占用少）
  num_workers: 4

# =============================================================================
# 训练超参数
# =============================================================================
training:
  # 训练轮数
  # 范围：1-1000，典型值：1-10
  # 更多轮次可能获得更好性能但有过拟合风险
  num_epochs: 3
  
  # 初始学习率
  # 范围：1e-6 到 1e-1，典型值：1e-5, 2e-5, 5e-5
  # 学习率决定模型学习速度
  learning_rate: 2.0e-5
  
  # 正则化的权重衰减系数
  # 范围：0-1，典型值：0.01, 0.1
  # 更高的值提供更强的正则化
  weight_decay: 0.01
  
  # 学习率调度器的预热步数
  # 范围：0+，典型值：100-1000
  # 预热有助于稳定早期训练
  warmup_steps: 500
  
  # 梯度累积步数
  # 范围：1-128，典型值：1, 2, 4, 8
  # 有效批次大小 = batch_size * gradient_accumulation_steps
  gradient_accumulation_steps: 4
  
  # 梯度裁剪的最大范数
  # 范围：0.1-10，典型值：0.5, 1.0, 5.0
  # 防止训练期间的梯度爆炸
  max_grad_norm: 1.0
  
  # 启用自动混合精度（AMP）训练
  # AMP 减少内存使用，可在现代 GPU 上加速训练
  # 推荐：V100, A100, RTX 20/30/40 系列使用 true
  use_amp: true

# =============================================================================
# 检查点和日志配置
# =============================================================================
checkpoints:
  # 模型检查点和日志的输出目录
  # 如果不存在将自动创建
  output_dir: "outputs"
  
  # 检查点保存间隔的训练步数
  # 范围：1+，典型值：500-5000
  # 更频繁的保存占用更多磁盘空间但提供更好的恢复性
  save_steps: 1000
  
  # 日志记录事件间隔的训练步数
  # 范围：1+，典型值：10-500
  # 更频繁的日志记录提供更好的监控
  logging_steps: 100
  
  # 评估运行间隔的训练步数
  # 范围：1+，典型值：100-2000
  # 更频繁的评估提供更好的监控但会减慢训练
  eval_steps: 500

# =============================================================================
# WandB 实验跟踪配置
# =============================================================================
wandb:
  # 实验组织的 WandB 项目名称
  # 应该是您 WandB 账户中的有效项目名
  project: "zero2llmv"
  
  # 实验运行名称（可选）
  # 留空以根据配置自动生成名称
  # 示例："vlm-baseline-experiment"
  name: ""
  
  # 实验描述和注释（可选）
  # 用于记录此训练运行的目的
  # 示例："使用默认超参数的基线 VLM 训练"
  notes: ""
  
  # 分类用的实验标签（可选）
  # 用于筛选和组织实验
  # 示例：["baseline", "vlm", "batch8", "lr2e-5"]
  tags: []

# =============================================================================
# 环境变量（出于安全考虑不包含在 YAML 中）
# =============================================================================
# 
# 以下敏感配置应该设置为环境变量：
#
# WANDB_API_KEY: 您的 WandB API 密钥用于身份验证
#   - 从 https://wandb.ai/authorize 获取
#   - 示例：export WANDB_API_KEY="your_api_key_here"
#
# WANDB_BASE_URL: 自定义 WandB 服务器 URL（用于自托管实例）
#   - 使用 wandb.ai 云服务时不设置
#   - 示例：export WANDB_BASE_URL="https://your-wandb-server.com"
#
# =============================================================================

# =============================================================================
# 配置提示
# =============================================================================
#
# 1. 内存优化：
#    - 遇到内存不足错误时减小 batch_size
#    - 对于上下文需求有限的模型减小 max_seq_length
#    - 启用 use_amp 可减少约 50% 的内存使用
#
# 2. 训练速度：
#    - 增加 batch_size 和/或 gradient_accumulation_steps 以加快训练
#    - 增加 num_workers（最多到 CPU 核心数）以加快数据加载
#    - 在现代 GPU 上使用 use_amp 可获得 20-50% 的加速
#
# 3. 模型质量：
#    - 增加 num_epochs 可能获得更好的性能
#    - 尝试不同的 learning_rate（如 1e-5, 2e-5, 5e-5）
#    - 使用 weight_decay 防止过拟合
#
# 4. 监控：
#    - 减小 logging_steps 以获得更详细的训练曲线
#    - 使用有意义的 wandb.name 和 wandb.tags 进行实验跟踪
#    - 训练期间定期检查 wandb 仪表板
#
# 5. 可复现性：
#    - 为每个实验保留此配置文件的副本
#    - 使用版本控制跟踪配置变化
#    - 在 wandb.notes 中记录任何手动修改
#
# =============================================================================